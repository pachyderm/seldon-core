{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Examples for SKlearn Prepackaged Server trained with Pachyderm and deployed to MinIO\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " * A kubernetes cluster with kubectl configured\n",
    " * curl\n",
    " * pygmentize\n",
    " * Python 3.7 locally (3.8 does not work, use pyenv if necessary)\n",
    "\n",
    "TODO: test with local minikube, ensure example works end to end with a totally fresh cluster (rather than working on pachub cluster and skipping some bits)\n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](seldon_core_setup.ipynb) to setup Seldon Core with an ingress.\n",
    "\n",
    "\n",
    "## Setup MinIO (TODO: remove this section)\n",
    "\n",
    "Use the provided [notebook](../../../notebooks/minio_setup.ipynb) to install Minio in your cluster and configure `mc` CLI tool. \n",
    "Instructions [also online](./minio_setup.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.8 (default, Aug  4 2020, 16:08:14) \\n[GCC 9.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python dependencies\n",
    "\n",
    "This tutorial will require you to install pandas and scikit-learn in followint versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn == 0.20.3\n",
      "numpy >= 1.8.2\n",
      "joblib >= 0.13.0\n",
      "pandas >= 1.0.1\n",
      "PyYAML >= 5.3\n"
     ]
    }
   ],
   "source": [
    "!cat iris-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do it by issuing following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.20.3\n",
      "  Using cached scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Collecting numpy>=1.8.2\n",
      "  Using cached numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting joblib>=0.13.0\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting pandas>=1.0.1\n",
      "  Using cached pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting scipy>=0.13.3\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 2.9 MB/s eta 0:00:01    |▊                               | 573 kB 1.8 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Using legacy setup.py install for PyYAML, since package 'wheel' is not installed.\n",
      "Installing collected packages: numpy, scipy, scikit-learn, joblib, six, python-dateutil, pytz, pandas, PyYAML\n",
      "    Running setup.py install for PyYAML ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyYAML-5.3.1 joblib-0.16.0 numpy-1.19.1 pandas-1.1.0 python-dateutil-2.8.1 pytz-2020.1 scikit-learn-0.20.3 scipy-1.5.2 six-1.15.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/luke/.pyenv/versions/3.7.8/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r iris-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pachyderm CLI (pachctl) client tool\n",
    "\n",
    "Follow steps relevant to your platform from official [documentation](https://docs.pachyderm.com/latest/getting_started/local_installation/#install-pachctl) in order to get the `pachctl` command line tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify correct client installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0-3ad6aa7344f90eeebedb6235eeb561bdded45879\n"
     ]
    }
   ],
   "source": [
    "!pachctl version --client-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pachyderm in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pachctl deploy Pachyderm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/pachyderm created\n",
      "serviceaccount/pachyderm created\n",
      "serviceaccount/pachyderm-worker created\n",
      "clusterrole.rbac.authorization.k8s.io/pachyderm created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/pachyderm created\n",
      "role.rbac.authorization.k8s.io/pachyderm-worker created\n",
      "rolebinding.rbac.authorization.k8s.io/pachyderm-worker created\n",
      "deployment.apps/etcd created\n",
      "service/etcd created\n",
      "service/pachd created\n",
      "service/pachd-peer created\n",
      "deployment.apps/pachd created\n",
      "service/dash created\n",
      "deployment.apps/dash created\n",
      "secret/pachyderm-storage-secret created\n",
      "\n",
      "Pachyderm is launching. Check its status with \"kubectl get all\"\n",
      "Once launched, access the dashboard by running \"pachctl port-forward\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create ns pachyderm\n",
    "pachctl deploy local --no-expose-docker-socket --namespace pachyderm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): deployments.apps \"pachd\" not found\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deployment pachd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### port-forward pachyderm to localhost\n",
    "\n",
    "in separate terminal:\n",
    "\n",
    "```bash\n",
    "pachctl port-forward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model using Pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And training data to Pachyderm \"iris-input\" repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the helper python script to pull iris training data from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGetting Iris Dataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    iris = datasets.load_iris()\n",
      "    X, y = iris.data, iris.target\n",
      "\n",
      "    data = pd.DataFrame(\n",
      "        data=np.c_[iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]],\n",
      "        columns=iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mfeature_names\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] + [\u001b[33m\"\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "    )\n",
      "\n",
      "    data.to_csv(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mIris dataset saved to \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m file\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize get-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can skip the following two commands unless you are debugging/cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for X in $(pachctl list repo --raw |jq -r .repo.name); do pachctl delete repo $X; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for X in $(pachctl list pipeline --raw |jq -r .pipeline.name); do pachctl delete pipeline $X; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke/Projects/Pachyderm/seldon-core/examples/pachyderm\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Getting Iris Dataset\n",
      "Iris dataset saved to 'data.csv' file\n"
     ]
    }
   ],
   "source": [
    "!python get-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put produced `data.csv` file into Pachyderm's  `iris-input` repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   CREATED                SIZE (MASTER) ACCESS LEVEL \n",
      "iris-data              Less than a second ago 0B            OWNER                                                                                           \n",
      "iris-trainer-01_build  59 seconds ago         54.83MiB      OWNER        Output repo for pipeline iris-trainer-01_build.                                    \n",
      "iris-trainer-01_source About a minute ago     54.57MiB      OWNER        python_pachyderm.create_python_pipeline: source code for pipeline iris-trainer-01. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pachctl create repo iris-data\n",
    "pachctl list repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we use following python script to pull training dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO      BRANCH COMMIT                           FINISHED               SIZE     PROGRESS DESCRIPTION\n",
      "iris-data master 18c0e92214374c3eb3b903436742972c Less than a second ago 3.005KiB -         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data.csv: 3.00 KiB / 3.00 KiB [===================================================] 100.00% ? p/s 0s"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pachctl put file iris-data@master -f data.csv\n",
    "pachctl list commit iris-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      TYPE SIZE     \n",
      "/data.csv file 3.005KiB \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris-data@master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pachyderm pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-pachyderm in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (6.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.2 in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from python-pachyderm) (3.12.4)\n",
      "Requirement already satisfied: grpcio>=1.26.0 in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from python-pachyderm) (1.31.0)\n",
      "Requirement already satisfied: setuptools in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from protobuf>=3.11.2->python-pachyderm) (47.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from protobuf>=3.11.2->python-pachyderm) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/luke/.pyenv/versions/3.7.8/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pachyderm Pipeline is defined by the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import python_pachyderm\n",
    "from os.path import expanduser\n",
    "\n",
    "def new_from_pach_config():\n",
    "    config = json.load(open(expanduser(\"~\")+\"/.pachyderm/config.json\"))\n",
    "    active = config[\"v2\"][\"active_context\"]\n",
    "    ctx = config[\"v2\"][\"contexts\"][active]\n",
    "    if \"session_token\" in ctx:\n",
    "        return python_pachyderm.Client.new_from_pachd_address(ctx[\"pachd_address\"], auth_token=ctx[\"session_token\"])\n",
    "    else:\n",
    "        return python_pachyderm.Client.new_from_pachd_address(ctx[\"pachd_address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x iris-trainer/build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import python_pachyderm\n",
    "import os\n",
    "client = new_from_pach_config()\n",
    "\n",
    "def relpath(path):\n",
    "    # https://stackoverflow.com/questions/52119454/how-to-obtain-jupyter-notebooks-path\n",
    "    return os.path.join(os.getcwd(), path)\n",
    "\n",
    "python_pachyderm.create_python_pipeline(\n",
    "    client,\n",
    "    relpath(\"iris-trainer\"),\n",
    "    python_pachyderm.Input(pfs=python_pachyderm.PFSInput(glob=\"/*\", repo=\"iris-data\")),\n",
    "    update=True, reprocess=True,\n",
    "    pipeline_name=\"iris-trainer-04\",\n",
    "    image=\"python:3.7\" # 3.8 breaks sklearn!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or more pipelines have encountered errors, use inspect pipeline to get more info.\n",
      "NAME                  VERSION INPUT                                                               CREATED           STATE / LAST JOB   DESCRIPTION                                                                            \n",
      "iris-trainer-04       1       (iris-data:/* ⨯ iris-trainer-04_build:/ ⨯ iris-trainer-04_source:/) 50 seconds ago    \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m                                                                                         \n",
      "iris-trainer-04_build 1       iris-trainer-04_source:/                                            53 seconds ago    \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m  python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-04. \n",
      "iris-trainer-03       1       (iris-data:/* ⨯ iris-trainer-03_build:/ ⨯ iris-trainer-03_source:/) 2 minutes ago     \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m                                                                                         \n",
      "iris-trainer-03_build 1       iris-trainer-03_source:/                                            2 minutes ago     \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m  python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-03. \n",
      "iris-trainer-02       1       (iris-data:/* ⨯ iris-trainer-02_build:/ ⨯ iris-trainer-02_source:/) About an hour ago \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m                                                                                         \n",
      "iris-trainer-02_build 1       iris-trainer-02_source:/                                            About an hour ago \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m  python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-02. \n",
      "iris-trainer-01       1       (iris-data:/* ⨯ iris-trainer-01_build:/ ⨯ iris-trainer-01_source:/) About an hour ago \u001b[32mrunning\u001b[0m / \u001b[31mfailure\u001b[0m                                                                                         \n",
      "iris-trainer-01_build 2       iris-trainer-01_source:/                                            About an hour ago \u001b[31mfailure\u001b[0m / \u001b[33mstarting\u001b[0m python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-01. \n"
     ]
    }
   ],
   "source": [
    "!pachctl list pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE              STARTED            DURATION           RESTART PROGRESS  DL       UL       STATE                                 \n",
      "f2cdc295fcc64c9cbdbd9c76a4e06da1 iris-trainer-04       26 seconds ago     18 seconds         0       1 + 0 / 1 56.43MiB 1.048KiB \u001b[32msuccess\u001b[0m                               \n",
      "a070c752f1c5438ebf5c23d049d37e4c iris-trainer-04_build 45 seconds ago     19 seconds         0       1 + 0 / 1 3.774KiB 56.43MiB \u001b[32msuccess\u001b[0m                               \n",
      "f741a69637e6440aae0df05bc7a011e5 iris-trainer-03       About a minute ago 27 seconds         0       1 + 0 / 1 56.24MiB 1.048KiB \u001b[32msuccess\u001b[0m                               \n",
      "c2a37dcb8de3411a9b8c1f3be29b42d1 iris-trainer-03_build 2 minutes ago      10 seconds         0       1 + 0 / 1 3.52KiB  56.23MiB \u001b[32msuccess\u001b[0m                               \n",
      "0715efaac53e46e5a6bc81532969555b iris-trainer-02       About an hour ago  27 seconds         0       1 + 0 / 1 109.4MiB 1.006KiB \u001b[32msuccess\u001b[0m                               \n",
      "7ad9fef80b004d46a5b0a2b6ebc3f42d iris-trainer-02_build About an hour ago  12 seconds         0       1 + 0 / 1 54.57MiB 54.83MiB \u001b[32msuccess\u001b[0m                               \n",
      "8d0ae72f17ee4f47911b6514d8530a4e iris-trainer-01       About an hour ago  Less than a second 0       0 + 0 / 0 0B       0B       \u001b[31mfailure\u001b[0m: inputs failed: iris-train... \n",
      "0212c42ac6b64a04b5716bbe6391afac iris-trainer-01_build About an hour ago  -                  0       0 + 0 / 0 0B       0B       \u001b[33mstarting\u001b[0m                              \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME TYPE SIZE \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris-trainer-01_build@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.7.8\n",
      "pip 20.2.1 from /usr/local/lib/python3.7/site-packages/pip (python 3.7)\n",
      "Collecting scikit-learn==0.23.2\n",
      "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting numpy>=1.8.2\n",
      "  Downloading numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Collecting joblib>=0.13.0\n",
      "  Downloading joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/joblib-0.16.0-py3-none-any.whl\n",
      "Collecting pandas>=1.0.1\n",
      "  Downloading pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting PyYAML>=5.3\n",
      "  Downloading PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/threadpoolctl-2.1.0-py3-none-any.whl\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/pytz-2020.1-py2.py3-none-any.whl\n",
      "Collecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "  Saved /pfs/.scratch/4e415c7530854a198de805b802082d2b/out/six-1.15.0-py2.py3-none-any.whl\n",
      "Skipping scikit-learn, due to already being wheel.\n",
      "Skipping numpy, due to already being wheel.\n",
      "Skipping joblib, due to already being wheel.\n",
      "Skipping pandas, due to already being wheel.\n",
      "Skipping scipy, due to already being wheel.\n",
      "Skipping threadpoolctl, due to already being wheel.\n",
      "Skipping python-dateutil, due to already being wheel.\n",
      "Skipping pytz, due to already being wheel.\n",
      "Skipping six, due to already being wheel.\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=471254 sha256=2e9d555e8d729f33ef23be7c519366f4abb2983ee15c2ed4f09249498c4d3db4\n",
      "  Stored in directory: /root/.cache/pip/wheels/5e/03/1e/e1e954795d6f35dfc7b637fe2277bff021303bd9570ecea653\n",
      "Successfully built PyYAML\n",
      "WARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --job=a070c752f1c5438ebf5c23d049d37e4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris\"\n",
    "  },\n",
    "  \"description\": \"A pipeline that trains simple Iris classifier.\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"/train_iris.py\" ],\n",
    "    \"image\": \"seldonio/pachyderm-iris-trainer:0.1\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris-data\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify pipeline success\n",
    "\n",
    "Give pachyderm a moment to process the pipeline first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE STARTED      DURATION  RESTART PROGRESS  DL       UL      STATE   \n",
      "145ae50e43e24019b923b823e2813eeb iris     18 hours ago 4 seconds 0       1 + 0 / 1 3.005KiB 1.01KiB \u001b[32msuccess\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO BRANCH COMMIT                           FINISHED     SIZE    PROGRESS DESCRIPTION\n",
      "iris master 74976e9cc5e540cbb4d61d370b350518 18 hours ago 1.01KiB -         \n"
     ]
    }
   ],
   "source": [
    "!pachctl list commit iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME          TYPE SIZE    \n",
      "/model.joblib file 1.01KiB \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile metadata.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris-meta\"\n",
    "  },\n",
    "  \"description\": \"Copy model over and create seldon metadata based on model commit in pachyderm\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"-c\", \"import os; import pprint; pprint.pprint(os.environ)\" ],\n",
    "    \"image\": \"python:3\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile metadata.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris-meta\"\n",
    "  },\n",
    "  \"description\": \"Copy model over and create seldon metadata based on model commit in pachyderm\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"-c\", \"import os; import pprint; pprint.pprint(dict(os.environ))\" ],\n",
    "    \"image\": \"python:3\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl update pipeline -f metadata.json --reprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE  STARTED      DURATION  RESTART PROGRESS  DL       UL      STATE   \n",
      "033e4477c8644139b0a0c1c03ec10000 iris-meta 1 second ago -         0       0 + 0 / 0 0B       0B      \u001b[33mrunning\u001b[0m \n",
      "145ae50e43e24019b923b823e2813eeb iris      3 days ago   4 seconds 0       1 + 0 / 1 3.005KiB 1.01KiB \u001b[32msuccess\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DASH_PORT': 'tcp://10.0.5.82:8080',\n",
      " 'DASH_PORT_8080_TCP': 'tcp://10.0.5.82:8080',\n",
      " 'DASH_PORT_8080_TCP_ADDR': '10.0.5.82',\n",
      " 'DASH_PORT_8080_TCP_PORT': '8080',\n",
      " 'DASH_PORT_8080_TCP_PROTO': 'tcp',\n",
      " 'DASH_PORT_8081_TCP': 'tcp://10.0.5.82:8081',\n",
      " 'DASH_PORT_8081_TCP_ADDR': '10.0.5.82',\n",
      " 'DASH_PORT_8081_TCP_PORT': '8081',\n",
      " 'DASH_PORT_8081_TCP_PROTO': 'tcp',\n",
      " 'DASH_SERVICE_HOST': '10.0.5.82',\n",
      " 'DASH_SERVICE_PORT': '8080',\n",
      " 'DASH_SERVICE_PORT_DASH_HTTP': '8080',\n",
      " 'DASH_SERVICE_PORT_GRPC_PROXY_HTTP': '8081',\n",
      " 'ETCD_PORT': 'tcp://10.0.4.103:2379',\n",
      " 'ETCD_PORT_2379_TCP': 'tcp://10.0.4.103:2379',\n",
      " 'ETCD_PORT_2379_TCP_ADDR': '10.0.4.103',\n",
      " 'ETCD_PORT_2379_TCP_PORT': '2379',\n",
      " 'ETCD_PORT_2379_TCP_PROTO': 'tcp',\n",
      " 'ETCD_SERVICE_HOST': '10.0.4.103',\n",
      " 'ETCD_SERVICE_PORT': '2379',\n",
      " 'ETCD_SERVICE_PORT_CLIENT_PORT': '2379',\n",
      " 'GOOGLE_BUCKET': 'hub-b0-h3ix16qcrp',\n",
      " 'GOOGLE_CRED': '',\n",
      " 'GPG_KEY': 'E3FF2839C048B25C084DEBE9B26995E310250568',\n",
      " 'HOME': '/root',\n",
      " 'HOSTNAME': 'pipeline-iris-meta-v7-9twzx',\n",
      " 'KUBERNETES_PORT': 'tcp://10.0.0.1:443',\n",
      " 'KUBERNETES_PORT_443_TCP': 'tcp://10.0.0.1:443',\n",
      " 'KUBERNETES_PORT_443_TCP_ADDR': '10.0.0.1',\n",
      " 'KUBERNETES_PORT_443_TCP_PORT': '443',\n",
      " 'KUBERNETES_PORT_443_TCP_PROTO': 'tcp',\n",
      " 'KUBERNETES_SERVICE_HOST': '10.0.0.1',\n",
      " 'KUBERNETES_SERVICE_PORT': '443',\n",
      " 'KUBERNETES_SERVICE_PORT_HTTPS': '443',\n",
      " 'LANG': 'C.UTF-8',\n",
      " 'LOKI_LOGGING': 'true',\n",
      " 'LOKI_PORT': 'tcp://10.0.14.191:3100',\n",
      " 'LOKI_PORT_3100_TCP': 'tcp://10.0.14.191:3100',\n",
      " 'LOKI_PORT_3100_TCP_ADDR': '10.0.14.191',\n",
      " 'LOKI_PORT_3100_TCP_PORT': '3100',\n",
      " 'LOKI_PORT_3100_TCP_PROTO': 'tcp',\n",
      " 'LOKI_SERVICE_HOST': '10.0.14.191',\n",
      " 'LOKI_SERVICE_PORT': '3100',\n",
      " 'LOKI_SERVICE_PORT_HTTP_METRICS': '3100',\n",
      " 'PACHD_LB_PORT': 'tcp://10.0.7.214:31400',\n",
      " 'PACHD_LB_PORT_30600_TCP': 'tcp://10.0.7.214:30600',\n",
      " 'PACHD_LB_PORT_30600_TCP_ADDR': '10.0.7.214',\n",
      " 'PACHD_LB_PORT_30600_TCP_PORT': '30600',\n",
      " 'PACHD_LB_PORT_30600_TCP_PROTO': 'tcp',\n",
      " 'PACHD_LB_PORT_31400_TCP': 'tcp://10.0.7.214:31400',\n",
      " 'PACHD_LB_PORT_31400_TCP_ADDR': '10.0.7.214',\n",
      " 'PACHD_LB_PORT_31400_TCP_PORT': '31400',\n",
      " 'PACHD_LB_PORT_31400_TCP_PROTO': 'tcp',\n",
      " 'PACHD_LB_SERVICE_HOST': '10.0.7.214',\n",
      " 'PACHD_LB_SERVICE_PORT': '31400',\n",
      " 'PACHD_LB_SERVICE_PORT_API_GRPC_PORT': '31400',\n",
      " 'PACHD_LB_SERVICE_PORT_S3_GATEWAY_PORT': '30600',\n",
      " 'PACHD_PORT': 'tcp://10.0.14.152:30653',\n",
      " 'PACHD_PORT_30600_TCP': 'tcp://10.0.14.152:30600',\n",
      " 'PACHD_PORT_30600_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30600_TCP_PORT': '30600',\n",
      " 'PACHD_PORT_30600_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30650_TCP': 'tcp://10.0.14.152:30650',\n",
      " 'PACHD_PORT_30650_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30650_TCP_PORT': '30650',\n",
      " 'PACHD_PORT_30650_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30651_TCP': 'tcp://10.0.14.152:30651',\n",
      " 'PACHD_PORT_30651_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30651_TCP_PORT': '30651',\n",
      " 'PACHD_PORT_30651_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30652_TCP': 'tcp://10.0.14.152:30652',\n",
      " 'PACHD_PORT_30652_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30652_TCP_PORT': '30652',\n",
      " 'PACHD_PORT_30652_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30653_TCP': 'tcp://10.0.14.152:30653',\n",
      " 'PACHD_PORT_30653_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30653_TCP_PORT': '30653',\n",
      " 'PACHD_PORT_30653_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30654_TCP': 'tcp://10.0.14.152:30654',\n",
      " 'PACHD_PORT_30654_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30654_TCP_PORT': '30654',\n",
      " 'PACHD_PORT_30654_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30999_TCP': 'tcp://10.0.14.152:30999',\n",
      " 'PACHD_PORT_30999_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30999_TCP_PORT': '30999',\n",
      " 'PACHD_PORT_30999_TCP_PROTO': 'tcp',\n",
      " 'PACHD_SERVICE_HOST': '10.0.14.152',\n",
      " 'PACHD_SERVICE_PORT': '30653',\n",
      " 'PACHD_SERVICE_PORT_API_GIT_PORT': '30999',\n",
      " 'PACHD_SERVICE_PORT_API_GRPC_PEER': '30653',\n",
      " 'PACHD_SERVICE_PORT_API_GRPC_PORT': '30650',\n",
      " 'PACHD_SERVICE_PORT_API_HTTP_PORT': '30652',\n",
      " 'PACHD_SERVICE_PORT_S3GATEWAY_PORT': '30600',\n",
      " 'PACHD_SERVICE_PORT_SAML_PORT': '30654',\n",
      " 'PACHD_SERVICE_PORT_TRACE_PORT': '30651',\n",
      " 'PACH_JOB_ID': '033e4477c8644139b0a0c1c03ec10000',\n",
      " 'PACH_NAMESPACE': 'default',\n",
      " 'PACH_OUTPUT_COMMIT_ID': 'd6df983db1b9439581280d6eaf3d6a19',\n",
      " 'PACH_ROOT': '/pach',\n",
      " 'PATH': '/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      " 'PEER_PORT': '653',\n",
      " 'PIPELINE_IRIS_META_V7_PORT': 'tcp://10.0.14.235:80',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP': 'tcp://10.0.14.235:80',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP_ADDR': '10.0.14.235',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP_PORT': '80',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP': 'tcp://10.0.14.235:9090',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP_ADDR': '10.0.14.235',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP_PORT': '9090',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_HOST': '10.0.14.235',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_PORT': '80',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_PORT_GRPC_PORT': '80',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_PORT_PROMETHEUS_METRICS': '9090',\n",
      " 'PIPELINE_IRIS_V1_PORT': 'tcp://10.0.2.27:80',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP': 'tcp://10.0.2.27:80',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP_ADDR': '10.0.2.27',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP_PORT': '80',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP': 'tcp://10.0.2.27:9090',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP_ADDR': '10.0.2.27',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP_PORT': '9090',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_HOST': '10.0.2.27',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_PORT': '80',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_PORT_GRPC_PORT': '80',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_PORT_PROMETHEUS_METRICS': '9090',\n",
      " 'PPS_ETCD_PREFIX': 'pachyderm/1.7.0/pachyderm_pps',\n",
      " 'PPS_PIPELINE_NAME': 'iris-meta',\n",
      " 'PPS_POD_NAME': 'pipeline-iris-meta-v7-9twzx',\n",
      " 'PPS_SPEC_COMMIT': 'e7b659d932a048b7baa8129f16e6aa9e',\n",
      " 'PPS_WORKER_GRPC_PORT': '80',\n",
      " 'PPS_WORKER_IP': '10.44.0.39',\n",
      " 'PYTHON_GET_PIP_SHA256': 'd4d62a0850fe0c2e6325b2cc20d818c580563de5a2038f917e3cb0e25280b4d1',\n",
      " 'PYTHON_GET_PIP_URL': 'https://github.com/pypa/get-pip/raw/5578af97f8b2b466f4cdbebe18a3ba2d48ad1434/get-pip.py',\n",
      " 'PYTHON_PIP_VERSION': '20.2.1',\n",
      " 'PYTHON_VERSION': '3.8.5',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT': 'tcp://10.0.4.11:80',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP': 'tcp://10.0.4.11:443',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP_ADDR': '10.0.4.11',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP_PORT': '443',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP_PROTO': 'tcp',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP': 'tcp://10.0.4.11:80',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP_ADDR': '10.0.4.11',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP_PORT': '80',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_HOST': '10.0.4.11',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_PORT': '80',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_PORT_HTTP': '80',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_PORT_HTTPS': '443',\n",
      " 'STORAGE_BACKEND': 'GOOGLE',\n",
      " 'iris': '/pfs/iris/model.joblib',\n",
      " 'iris_COMMIT': '74976e9cc5e540cbb4d61d370b350518'}\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --job 033e4477c8644139b0a0c1c03ec10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return logs from a job.\n",
      "\n",
      "Usage:\n",
      "  pachctl logs [--pipeline=<pipeline>|--job=<job>] [--datum=<datum>] [flags]\n",
      "\n",
      "Examples:\n",
      "\n",
      "# Return logs emitted by recent jobs in the \"filter\" pipeline\n",
      "$ pachctl logs --pipeline=filter\n",
      "\n",
      "# Return logs emitted by the job aedfa12aedf\n",
      "$ pachctl logs --job=aedfa12aedf\n",
      "\n",
      "# Return logs emitted by the pipeline \\\"filter\\\" while processing /apple.txt and a file with the hash 123aef\n",
      "$ pachctl logs --pipeline=filter --inputs=/apple.txt,123aef\n",
      "\n",
      "Flags:\n",
      "      --datum string      Filter for log lines for this datum (accepts datum ID)\n",
      "  -f, --follow            Follow logs as more are created.\n",
      "  -h, --help              help for logs\n",
      "      --inputs string     Filter for log lines generated while processing these files (accepts PFS paths or file hashes)\n",
      "  -j, --job string        Filter for log lines from this job (accepts job ID)\n",
      "      --master            Return log messages from the master process (pipeline must be set).\n",
      "  -p, --pipeline string   Filter the log for lines from this pipeline (accepts pipeline name)\n",
      "      --raw               Return log messages verbatim from server.\n",
      "  -t, --tail int          Lines of recent logs to display.\n",
      "      --worker            Return log messages from the worker process.\n",
      "\n",
      "Global Flags:\n",
      "      --no-color   Turn off colors.\n",
      "  -v, --verbose    Output verbose logs\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add trained model to remote S3 storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadata.yaml \n",
    "\n",
    "In metadata we can use Pachyderm's hash to version deployed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitId = !pachctl list commit iris --raw |jq -r .commit.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitId = commitId[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"metadata.yaml\", \"w\")\n",
    "\n",
    "f.write(f\"\"\"name: iris\n",
    "versions: [iris/pachyderm:{commitId}]\n",
    "platform: sklearn\n",
    "inputs:\n",
    "- datatype: BYTES\n",
    "  name: input\n",
    "  shape: [ 1, 4 ]\n",
    "outputs:\n",
    "- datatype: BYTES\n",
    "  name: output\n",
    "  shape: [ 3 ]\"\"\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Extend the above pachyderm pipeline to output to a repo which contains the model from the previous pipeline stage along with the metadata.yml with \n",
    "\n",
    "Then we can automatically generate the Seldon metadata for a versioned model whenever the data changes, which is cool.\n",
    "\n",
    "Also: how to access the Pach S3 gateway? Look at the docs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metadata to Pachyderm\n",
    "\n",
    "This is so that Seldon can fetch it via Pachyderm's S3 gateway, which allows Seldon to access files in Pachyderm using the S3 protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.yaml: 203 B / 203 B [================================] 100.00% ? p/s 0s\n",
      "cannot start a commit on an output branch\n"
     ]
    }
   ],
   "source": [
    "!pachctl put file iris@master -f metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bucket for our trained model and push it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket created successfully `minio-seldon/pachyderm-iris`.\n",
      "`model.joblib` -> `minio-seldon/pachyderm-iris/model.joblib`\n",
      "Total: 0 B, Transferred: 1.01 KiB, Speed: 146.70 KiB/s\n",
      "`metadata.yaml` -> `minio-seldon/pachyderm-iris/metadata.yaml`\n",
      "Total: 0 B, Transferred: 205 B, Speed: 24.81 KiB/s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mc mb minio-seldon/pachyderm-iris -p\n",
    "\n",
    "mc cp model.joblib minio-seldon/pachyderm-iris/\n",
    "mc cp metadata.yaml minio-seldon/pachyderm-iris/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2020-05-24 18:53:00 BST] \u001b[0m\u001b[33m   205B \u001b[0m\u001b[1mmetadata.yaml\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2020-05-24 18:53:00 BST] \u001b[0m\u001b[33m 1.0KiB \u001b[0m\u001b[1mmodel.joblib\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mc ls minio-seldon/pachyderm-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy sklearn server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting secret.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile secret.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: seldon-init-container-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "  AWS_ENDPOINT_URL: http://minio.minio-system.svc.cluster.local:9000\n",
    "  USE_SSL: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/seldon-init-container-secret configured\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f secret.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: pachyderm-sklearn\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/executor: \"true\"\n",
    "  name: iris\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: s3://pachyderm-iris\n",
    "      envSecretRefName: seldon-init-container-secret\n",
    "      name: classifier\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/pachyderm-sklearn created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f deploy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"pachyderm-sklearn-default-0-classifier\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"pachyderm-sklearn-default-0-classifier\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=pachyderm-sklearn -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"names\": [\n",
      "      \"t:0\",\n",
      "      \"t:1\",\n",
      "      \"t:2\"\n",
      "    ],\n",
      "    \"ndarray\": [\n",
      "      [\n",
      "        0.9548873249364185,\n",
      "        0.04505474761561256,\n",
      "        5.792744796895459e-05\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\":{\"ndarray\":[[5.964, 4.006, 2.081, 1.031]]}}' \\\n",
    "    http://localhost:8003/seldon/seldon/pachyderm-sklearn/api/v1.0/predictions  | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model metadata (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"name\": \"input\",\n",
      "      \"shape\": [\n",
      "        1,\n",
      "        4\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"name\": \"iris\",\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"name\": \"output\",\n",
      "      \"shape\": [\n",
      "        3\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"platform\": \"sklearn\",\n",
      "  \"versions\": [\n",
      "    \"iris/pachyderm:f8849a38b3f64c4b8998abf1f732f486\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s http://localhost:8003/seldon/seldon/pachyderm-sklearn/api/v1.0/metadata/classifier | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"pachyderm-sklearn\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deploy.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
