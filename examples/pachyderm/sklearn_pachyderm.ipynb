{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Examples for SKlearn Prepackaged Server trained with Pachyderm and deployed to MinIO\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " * A kubernetes cluster with kubectl configured\n",
    " * curl\n",
    " * pygmentize\n",
    " * Python 3.7 locally (3.8 does not work, use pyenv if necessary)\n",
    "\n",
    "TODO: test with local minikube, ensure example works end to end with a totally fresh cluster (rather than working on pachub cluster and skipping some bits)\n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](seldon_core_setup.ipynb) to setup Seldon Core with an ingress.\n",
    "\n",
    "\n",
    "## Setup MinIO (TODO: remove this section)\n",
    "\n",
    "Use the provided [notebook](../../../notebooks/minio_setup.ipynb) to install Minio in your cluster and configure `mc` CLI tool. \n",
    "Instructions [also online](./minio_setup.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.8 (default, Aug  4 2020, 16:08:14) \\n[GCC 9.3.0]'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python dependencies\n",
    "\n",
    "This tutorial will require you to install pandas and scikit-learn in followint versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn == 0.20.3\n",
      "numpy >= 1.8.2\n",
      "joblib >= 0.13.0\n",
      "pandas >= 1.0.1\n",
      "PyYAML >= 5.3\n"
     ]
    }
   ],
   "source": [
    "!cat iris-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do it by issuing following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.20.3\n",
      "  Using cached scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Collecting numpy>=1.8.2\n",
      "  Using cached numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting joblib>=0.13.0\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting pandas>=1.0.1\n",
      "  Using cached pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting scipy>=0.13.3\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 2.9 MB/s eta 0:00:01    |▊                               | 573 kB 1.8 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Using legacy setup.py install for PyYAML, since package 'wheel' is not installed.\n",
      "Installing collected packages: numpy, scipy, scikit-learn, joblib, six, python-dateutil, pytz, pandas, PyYAML\n",
      "    Running setup.py install for PyYAML ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyYAML-5.3.1 joblib-0.16.0 numpy-1.19.1 pandas-1.1.0 python-dateutil-2.8.1 pytz-2020.1 scikit-learn-0.20.3 scipy-1.5.2 six-1.15.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/luke/.pyenv/versions/3.7.8/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r iris-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pachyderm CLI (pachctl) client tool\n",
    "\n",
    "Follow steps relevant to your platform from official [documentation](https://docs.pachyderm.com/latest/getting_started/local_installation/#install-pachctl) in order to get the `pachctl` command line tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify correct client installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0-3ad6aa7344f90eeebedb6235eeb561bdded45879\n"
     ]
    }
   ],
   "source": [
    "!pachctl version --client-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pachyderm in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pachctl deploy Pachyderm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/pachyderm created\n",
      "serviceaccount/pachyderm created\n",
      "serviceaccount/pachyderm-worker created\n",
      "clusterrole.rbac.authorization.k8s.io/pachyderm created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/pachyderm created\n",
      "role.rbac.authorization.k8s.io/pachyderm-worker created\n",
      "rolebinding.rbac.authorization.k8s.io/pachyderm-worker created\n",
      "deployment.apps/etcd created\n",
      "service/etcd created\n",
      "service/pachd created\n",
      "service/pachd-peer created\n",
      "deployment.apps/pachd created\n",
      "service/dash created\n",
      "deployment.apps/dash created\n",
      "secret/pachyderm-storage-secret created\n",
      "\n",
      "Pachyderm is launching. Check its status with \"kubectl get all\"\n",
      "Once launched, access the dashboard by running \"pachctl port-forward\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create ns pachyderm\n",
    "pachctl deploy local --no-expose-docker-socket --namespace pachyderm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): deployments.apps \"pachd\" not found\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deployment pachd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### port-forward pachyderm to localhost\n",
    "\n",
    "in separate terminal:\n",
    "\n",
    "```bash\n",
    "pachctl port-forward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model using Pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And training data to Pachyderm \"iris-input\" repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the helper python script to pull iris training data from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGetting Iris Dataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    iris = datasets.load_iris()\n",
      "    X, y = iris.data, iris.target\n",
      "\n",
      "    data = pd.DataFrame(\n",
      "        data=np.c_[iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]],\n",
      "        columns=iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mfeature_names\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] + [\u001b[33m\"\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "    )\n",
      "\n",
      "    data.to_csv(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mIris dataset saved to \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m file\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize get-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can skip the following two commands unless you are debugging/cleaning up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for X in $(pachctl list repo --raw |jq -r .repo.name); do pachctl delete repo $X; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "!for X in $(pachctl list pipeline --raw |jq -r .pipeline.name); do pachctl delete pipeline $X; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke/Projects/Pachyderm/seldon-core/examples/pachyderm\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Getting Iris Dataset\n",
      "Iris dataset saved to 'data.csv' file\n"
     ]
    }
   ],
   "source": [
    "!python get-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put produced `data.csv` file into Pachyderm's  `iris-input` repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                   CREATED                SIZE (MASTER) ACCESS LEVEL \n",
      "iris-data              Less than a second ago 0B            OWNER                                                                                           \n",
      "iris-trainer-01_build  59 seconds ago         54.83MiB      OWNER        Output repo for pipeline iris-trainer-01_build.                                    \n",
      "iris-trainer-01_source About a minute ago     54.57MiB      OWNER        python_pachyderm.create_python_pipeline: source code for pipeline iris-trainer-01. \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pachctl create repo iris-data\n",
    "pachctl list repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we use following python script to pull training dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO      BRANCH COMMIT                           FINISHED               SIZE     PROGRESS DESCRIPTION\n",
      "iris-data master 18c0e92214374c3eb3b903436742972c Less than a second ago 3.005KiB -         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data.csv: 3.00 KiB / 3.00 KiB [===================================================] 100.00% ? p/s 0s"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pachctl put file iris-data@master -f data.csv\n",
    "pachctl list commit iris-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      TYPE SIZE     \n",
      "/data.csv file 3.005KiB \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris-data@master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pachyderm pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-pachyderm in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (6.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.2 in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from python-pachyderm) (3.12.4)\n",
      "Requirement already satisfied: grpcio>=1.26.0 in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from python-pachyderm) (1.31.0)\n",
      "Requirement already satisfied: setuptools in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from protobuf>=3.11.2->python-pachyderm) (47.1.0)\n",
      "Requirement already satisfied: six>=1.9 in /home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages (from protobuf>=3.11.2->python-pachyderm) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/luke/.pyenv/versions/3.7.8/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install python-pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pachyderm Pipeline is defined by the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import python_pachyderm\n",
    "from os.path import expanduser\n",
    "\n",
    "def new_from_pach_config():\n",
    "    config = json.load(open(expanduser(\"~\")+\"/.pachyderm/config.json\"))\n",
    "    active = config[\"v2\"][\"active_context\"]\n",
    "    ctx = config[\"v2\"][\"contexts\"][active]\n",
    "    if \"session_token\" in ctx:\n",
    "        return python_pachyderm.Client.new_from_pachd_address(ctx[\"pachd_address\"], auth_token=ctx[\"session_token\"])\n",
    "    else:\n",
    "        return python_pachyderm.Client.new_from_pachd_address(ctx[\"pachd_address\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "!chmod +x iris-trainer/build.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import python_pachyderm\n",
    "import os\n",
    "client = new_from_pach_config()\n",
    "\n",
    "def relpath(path):\n",
    "    # https://stackoverflow.com/questions/52119454/how-to-obtain-jupyter-notebooks-path\n",
    "    return os.path.join(os.getcwd(), path)\n",
    "\n",
    "python_pachyderm.create_python_pipeline(\n",
    "    client,\n",
    "    relpath(\"iris-trainer\"),\n",
    "    python_pachyderm.Input(pfs=python_pachyderm.PFSInput(glob=\"/*\", repo=\"iris-data\")),\n",
    "    update=True, reprocess=True,\n",
    "    pipeline_name=\"iris-trainer-02\",\n",
    "    image=\"python:3.7\" # 3.8 breaks sklearn!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or more pipelines have encountered errors, use inspect pipeline to get more info.\n",
      "NAME                  VERSION INPUT                                                               CREATED       STATE / LAST JOB   DESCRIPTION                                                                            \n",
      "iris-trainer-02       1       (iris-data:/* ⨯ iris-trainer-02_build:/ ⨯ iris-trainer-02_source:/) 2 minutes ago \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m                                                                                         \n",
      "iris-trainer-02_build 1       iris-trainer-02_source:/                                            2 minutes ago \u001b[32mrunning\u001b[0m / \u001b[32msuccess\u001b[0m  python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-02. \n",
      "iris-trainer-01       1       (iris-data:/* ⨯ iris-trainer-01_build:/ ⨯ iris-trainer-01_source:/) 6 minutes ago \u001b[32mrunning\u001b[0m / \u001b[31mfailure\u001b[0m                                                                                         \n",
      "iris-trainer-01_build 2       iris-trainer-01_source:/                                            7 minutes ago \u001b[31mfailure\u001b[0m / \u001b[33mstarting\u001b[0m python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-01. \n"
     ]
    }
   ],
   "source": [
    "!pachctl list pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One or more pipelines have encountered errors, use inspect pipeline to get more info.\n",
      "NAME                  VERSION INPUT                                                               CREATED       STATE / LAST JOB   DESCRIPTION                                                                            \n",
      "iris-trainer-01       1       (iris-data:/* ⨯ iris-trainer-01_build:/ ⨯ iris-trainer-01_source:/) 2 minutes ago \u001b[32mrunning\u001b[0m / \u001b[31mfailure\u001b[0m                                                                                         \n",
      "iris-trainer-01_build 2       iris-trainer-01_source:/                                            3 minutes ago \u001b[31mfailure\u001b[0m / \u001b[33mstarting\u001b[0m python_pachyderm.create_python_pipeline: build artifacts for pipeline iris-trainer-01. \n"
     ]
    }
   ],
   "source": [
    "!pachctl list pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE              STARTED       DURATION           RESTART PROGRESS  DL       UL       STATE                                 \n",
      "0715efaac53e46e5a6bc81532969555b iris-trainer-02       2 minutes ago 27 seconds         0       1 + 0 / 1 109.4MiB 1.006KiB \u001b[32msuccess\u001b[0m                               \n",
      "7ad9fef80b004d46a5b0a2b6ebc3f42d iris-trainer-02_build 2 minutes ago 12 seconds         0       1 + 0 / 1 54.57MiB 54.83MiB \u001b[32msuccess\u001b[0m                               \n",
      "8d0ae72f17ee4f47911b6514d8530a4e iris-trainer-01       6 minutes ago Less than a second 0       0 + 0 / 0 0B       0B       \u001b[31mfailure\u001b[0m: inputs failed: iris-train... \n",
      "0212c42ac6b64a04b5716bbe6391afac iris-trainer-01_build 7 minutes ago -                  0       0 + 0 / 0 0B       0B       \u001b[33mstarting\u001b[0m                              \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME TYPE SIZE \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris-trainer-01_build@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ ID=02\n",
      "+ env\n",
      "iris-trainer-02_build=/pfs/iris-trainer-02_build\n",
      "iris-trainer-02_source=/pfs/iris-trainer-02_source\n",
      "iris-data=/pfs/iris-data/data.csv\n",
      "iris-trainer-02_source_COMMIT=aefa7cc933894144b01915093134f4a2\n",
      "iris-data_COMMIT=18c0e92214374c3eb3b903436742972c\n",
      "iris-trainer-02_build_COMMIT=7cf8c6707aa24b61a9d2a5bffb5321b6\n",
      "KUBERNETES_SERVICE_PORT_HTTPS=443\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_80_TCP_ADDR=10.0.5.94\n",
      "PACHD_PORT=tcp://10.0.14.152:30653\n",
      "RELEASE_NAME_TRAEFIK_PORT_80_TCP_ADDR=10.0.4.11\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT=tcp://10.0.0.172:80\n",
      "+ echo 'Starting run 02'\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_80_TCP_PROTO=tcp\n",
      "PPS_PIPELINE_NAME=iris-trainer-02\n",
      "+ cd /pfs/iris-trainer-02_source\n",
      "+ pip install /pfs/iris-trainer-02_build/joblib-0.16.0-py3-none-any.whl /pfs/iris-trainer-02_build/numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl /pfs/iris-trainer-02_build/pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl /pfs/iris-trainer-02_build/python_dateutil-2.8.1-py2.py3-none-any.whl /pfs/iris-trainer-02_build/pytz-2020.1-py2.py3-none-any.whl /pfs/iris-trainer-02_build/scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl /pfs/iris-trainer-02_build/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl /pfs/iris-trainer-02_build/six-1.15.0-py2.py3-none-any.whl /pfs/iris-trainer-02_build/PyYAML-5.3.1.tar.gz\n",
      "PACHD_PORT_30654_TCP_PORT=30654\n",
      "PACHD_PORT_30653_TCP=tcp://10.0.14.152:30653\n",
      "KUBERNETES_SERVICE_PORT=443\n",
      "PACHD_LB_PORT_30600_TCP_ADDR=10.0.7.214\n",
      "GOOGLE_BUCKET=hub-b0-h3ix16qcrp\n",
      "HOSTNAME=pipeline-iris-trainer-02-v1-mczns\n",
      "PYTHON_VERSION=3.7.8\n",
      "PACH_ROOT=/pach\n",
      "GOOGLE_CRED=\n",
      "PACHD_LB_SERVICE_PORT_API_GRPC_PORT=31400\n",
      "PACHD_PORT_30654_TCP=tcp://10.0.14.152:30654\n",
      "RELEASE_NAME_TRAEFIK_PORT_80_TCP=tcp://10.0.4.11:80\n",
      "PACHD_SERVICE_PORT_API_GRPC_PORT=30650\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_9090_TCP_ADDR=10.0.0.172\n",
      "PACH_OUTPUT_COMMIT_ID=2af0f8cdbd6b46a0813b526abff4e203\n",
      "RELEASE_NAME_TRAEFIK_PORT_443_TCP_ADDR=10.0.4.11\n",
      "ETCD_SERVICE_HOST=10.0.4.103\n",
      "PACHD_SERVICE_PORT_API_GIT_PORT=30999\n",
      "PACHD_LB_PORT_30600_TCP=tcp://10.0.7.214:30600\n",
      "PACHD_PORT_30650_TCP_PROTO=tcp\n",
      "ETCD_PORT_2379_TCP=tcp://10.0.4.103:2379\n",
      "PACHD_LB_PORT_31400_TCP_ADDR=10.0.7.214\n",
      "LOKI_PORT_3100_TCP_PROTO=tcp\n",
      "DASH_PORT_8081_TCP_PORT=8081\n",
      "PACHD_PORT_30654_TCP_ADDR=10.0.14.152\n",
      "PACHD_PORT_30650_TCP_ADDR=10.0.14.152\n",
      "PACHD_LB_PORT=tcp://10.0.7.214:31400\n",
      "DASH_SERVICE_HOST=10.0.5.82\n",
      "PWD=/\n",
      "LOKI_SERVICE_HOST=10.0.14.191\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_9090_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_01_V1_SERVICE_PORT_GRPC_PORT=80\n",
      "LOKI_PORT_3100_TCP=tcp://10.0.14.191:3100\n",
      "PIPELINE_IRIS_TRAINER_01_V1_SERVICE_HOST=10.0.3.127\n",
      "PACHD_PORT_30652_TCP_ADDR=10.0.14.152\n",
      "RELEASE_NAME_TRAEFIK_SERVICE_PORT_HTTPS=443\n",
      "DASH_PORT_8080_TCP_ADDR=10.0.5.82\n",
      "PACHD_PORT_30652_TCP_PROTO=tcp\n",
      "LOKI_PORT_3100_TCP_ADDR=10.0.14.191\n",
      "RELEASE_NAME_TRAEFIK_PORT_443_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_01_V1_SERVICE_PORT_PROMETHEUS_METRICS=9090\n",
      "PIPELINE_IRIS_TRAINER_02_V1_SERVICE_HOST=10.0.0.172\n",
      "DASH_PORT_8081_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_80_TCP_PORT=80\n",
      "DASH_PORT_8080_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_80_TCP=tcp://10.0.5.94:80\n",
      "HOME=/root\n",
      "LANG=C.UTF-8\n",
      "DASH_PORT_8081_TCP=tcp://10.0.5.82:8081\n",
      "KUBERNETES_PORT_443_TCP=tcp://10.0.0.1:443\n",
      "PACHD_LB_PORT_30600_TCP_PROTO=tcp\n",
      "DASH_SERVICE_PORT_DASH_HTTP=8080\n",
      "PPS_WORKER_GRPC_PORT=80\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_80_TCP=tcp://10.0.0.172:80\n",
      "PACHD_SERVICE_PORT_S3GATEWAY_PORT=30600\n",
      "DASH_SERVICE_PORT_GRPC_PROXY_HTTP=8081\n",
      "ETCD_PORT_2379_TCP_PORT=2379\n",
      "PACHD_PORT_30651_TCP_PORT=30651\n",
      "GPG_KEY=0D96DF4D4110E5C43FBFB17F2D347EA6AA65421D\n",
      "PACHD_SERVICE_PORT=30653\n",
      "ETCD_PORT_2379_TCP_ADDR=10.0.4.103\n",
      "STORAGE_BACKEND=GOOGLE\n",
      "PACHD_SERVICE_PORT_TRACE_PORT=30651\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_9090_TCP=tcp://10.0.3.127:9090\n",
      "PACHD_PORT_30600_TCP=tcp://10.0.14.152:30600\n",
      "PPS_WORKER_IP=10.44.0.74\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_80_TCP_PORT=80\n",
      "PACHD_LB_SERVICE_HOST=10.0.7.214\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_80_TCP=tcp://10.0.3.127:80\n",
      "PACHD_PORT_30600_TCP_PORT=30600\n",
      "RELEASE_NAME_TRAEFIK_PORT_80_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_80_TCP_PORT=80\n",
      "DASH_PORT=tcp://10.0.5.82:8080\n",
      "PACHD_PORT_30999_TCP_PORT=30999\n",
      "LOKI_PORT_3100_TCP_PORT=3100\n",
      "PACHD_PORT_30999_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_SERVICE_PORT=80\n",
      "PACHD_SERVICE_PORT_API_HTTP_PORT=30652\n",
      "LOKI_SERVICE_PORT=3100\n",
      "PACHD_PORT_30650_TCP=tcp://10.0.14.152:30650\n",
      "PACHD_PORT_30653_TCP_ADDR=10.0.14.152\n",
      "PACHD_LB_PORT_31400_TCP=tcp://10.0.7.214:31400\n",
      "RELEASE_NAME_TRAEFIK_PORT=tcp://10.0.4.11:80\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_9090_TCP=tcp://10.0.0.172:9090\n",
      "PACHD_SERVICE_PORT_SAML_PORT=30654\n",
      "PACHD_PORT_30651_TCP=tcp://10.0.14.152:30651\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_9090_TCP_PORT=9090\n",
      "PIPELINE_IRIS_TRAINER_02_V1_SERVICE_PORT_GRPC_PORT=80\n",
      "LOKI_PORT=tcp://10.0.14.191:3100\n",
      "PIPELINE_IRIS_TRAINER_02_V1_SERVICE_PORT=80\n",
      "DASH_PORT_8080_TCP_PORT=8080\n",
      "PACHD_SERVICE_PORT_API_GRPC_PEER=30653\n",
      "PACHD_PORT_30600_TCP_PROTO=tcp\n",
      "RELEASE_NAME_TRAEFIK_PORT_80_TCP_PORT=80\n",
      "PACHD_PORT_30654_TCP_PROTO=tcp\n",
      "SHLVL=1\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_9090_TCP_PROTO=tcp\n",
      "RELEASE_NAME_TRAEFIK_SERVICE_PORT_HTTP=80\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_80_TCP_PROTO=tcp\n",
      "PACHD_LB_PORT_30600_TCP_PORT=30600\n",
      "KUBERNETES_PORT_443_TCP_PROTO=tcp\n",
      "PPS_SPEC_COMMIT=045be9a907da477f8ff206da2ada812f\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_9090_TCP_PROTO=tcp\n",
      "PPS_POD_NAME=pipeline-iris-trainer-02-v1-mczns\n",
      "PACHD_LB_PORT_31400_TCP_PORT=31400\n",
      "PACHD_SERVICE_HOST=10.0.14.152\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_80_TCP_ADDR=10.0.3.127\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_9090_TCP_ADDR=10.0.5.94\n",
      "PYTHON_PIP_VERSION=20.2.1\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_SERVICE_PORT_GRPC_PORT=80\n",
      "KUBERNETES_PORT_443_TCP_ADDR=10.0.0.1\n",
      "RELEASE_NAME_TRAEFIK_PORT_443_TCP=tcp://10.0.4.11:443\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT_9090_TCP_ADDR=10.0.3.127\n",
      "PACHD_PORT_30651_TCP_PROTO=tcp\n",
      "PACHD_LB_SERVICE_PORT_S3_GATEWAY_PORT=30600\n",
      "PACHD_PORT_30653_TCP_PORT=30653\n",
      "PACHD_PORT_30600_TCP_ADDR=10.0.14.152\n",
      "PIPELINE_IRIS_TRAINER_02_V1_SERVICE_PORT_PROMETHEUS_METRICS=9090\n",
      "RELEASE_NAME_TRAEFIK_SERVICE_PORT=80\n",
      "DASH_PORT_8081_TCP_ADDR=10.0.5.82\n",
      "PYTHON_GET_PIP_SHA256=d4d62a0850fe0c2e6325b2cc20d818c580563de5a2038f917e3cb0e25280b4d1\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_9090_TCP=tcp://10.0.5.94:9090\n",
      "PACHD_PORT_30999_TCP=tcp://10.0.14.152:30999\n",
      "PACHD_PORT_30652_TCP_PORT=30652\n",
      "LOKI_SERVICE_PORT_HTTP_METRICS=3100\n",
      "PACH_JOB_ID=0715efaac53e46e5a6bc81532969555b\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_SERVICE_PORT_PROMETHEUS_METRICS=9090\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_SERVICE_HOST=10.0.5.94\n",
      "PIPELINE_IRIS_TRAINER_01_V1_SERVICE_PORT=80\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_9090_TCP_PORT=9090\n",
      "KUBERNETES_SERVICE_HOST=10.0.0.1\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_80_TCP_PROTO=tcp\n",
      "KUBERNETES_PORT=tcp://10.0.0.1:443\n",
      "PACHD_LB_SERVICE_PORT=31400\n",
      "KUBERNETES_PORT_443_TCP_PORT=443\n",
      "DASH_PORT_8080_TCP=tcp://10.0.5.82:8080\n",
      "PACHD_PORT_30650_TCP_PORT=30650\n",
      "PYTHON_GET_PIP_URL=https://github.com/pypa/get-pip/raw/5578af97f8b2b466f4cdbebe18a3ba2d48ad1434/get-pip.py\n",
      "PACHD_LB_PORT_31400_TCP_PROTO=tcp\n",
      "PACHD_PORT_30651_TCP_ADDR=10.0.14.152\n",
      "PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n",
      "LOKI_LOGGING=true\n",
      "PEER_PORT=653\n",
      "PACH_NAMESPACE=default\n",
      "PACHD_PORT_30999_TCP_ADDR=10.0.14.152\n",
      "ETCD_PORT_2379_TCP_PROTO=tcp\n",
      "RELEASE_NAME_TRAEFIK_PORT_443_TCP_PORT=443\n",
      "ETCD_SERVICE_PORT_CLIENT_PORT=2379\n",
      "PIPELINE_IRIS_TRAINER_01_V1_PORT=tcp://10.0.3.127:80\n",
      "PACHD_PORT_30653_TCP_PROTO=tcp\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT_9090_TCP_PORT=9090\n",
      "DASH_SERVICE_PORT=8080\n",
      "PIPELINE_IRIS_TRAINER_02_BUILD_V1_PORT=tcp://10.0.5.94:80\n",
      "PACHD_PORT_30652_TCP=tcp://10.0.14.152:30652\n",
      "PPS_ETCD_PREFIX=pachyderm/1.7.0/pachyderm_pps\n",
      "ETCD_SERVICE_PORT=2379\n",
      "ETCD_PORT=tcp://10.0.4.103:2379\n",
      "PIPELINE_IRIS_TRAINER_02_V1_PORT_80_TCP_ADDR=10.0.0.172\n",
      "RELEASE_NAME_TRAEFIK_SERVICE_HOST=10.0.4.11\n",
      "_=/usr/bin/env\n",
      "Starting run 02\n",
      "Processing /pfs/iris-trainer-02_build/PyYAML-5.3.1.tar.gz\n",
      "Processing /pfs/iris-trainer-02_build/joblib-0.16.0-py3-none-any.whl\n",
      "Processing /pfs/iris-trainer-02_build/numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl\n",
      "Processing /pfs/iris-trainer-02_build/pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Processing /pfs/iris-trainer-02_build/python_dateutil-2.8.1-py2.py3-none-any.whl\n",
      "Processing /pfs/iris-trainer-02_build/pytz-2020.1-py2.py3-none-any.whl\n",
      "Processing /pfs/iris-trainer-02_build/scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Processing /pfs/iris-trainer-02_build/scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl\n",
      "Processing /pfs/iris-trainer-02_build/six-1.15.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: PyYAML\n",
      "  Building wheel for PyYAML (setup.py): started\n",
      "  Building wheel for PyYAML (setup.py): finished with status 'done'\n",
      "  Created wheel for PyYAML: filename=PyYAML-5.3.1-cp37-cp37m-linux_x86_64.whl size=471258 sha256=10838aeaef41d093e76b8397fb4e85bcd85a708fc9adcc02c04fb625afff3442\n",
      "  Stored in directory: /root/.cache/pip/wheels/28/c7/db/940fe569602229c9512464a9dd390978e1a594bf1748b4df65\n",
      "Successfully built PyYAML\n",
      "Installing collected packages: joblib, numpy, six, python-dateutil, pytz, pandas, scipy, scikit-learn, PyYAML\n",
      "Successfully installed PyYAML-5.3.1 joblib-0.16.0 numpy-1.19.1 pandas-1.1.0 python-dateutil-2.8.1 pytz-2020.1 scikit-learn-0.20.3 scipy-1.5.2 six-1.15.0\n",
      "+ python main.py\n",
      "Loading iris data set from /pfs/iris-data/data.csv\n",
      "Dataset loaded!\n",
      "Training model...\n",
      "Model trained!\n",
      "Saving model in /pfs/out/model.joblib\n",
      "Model saved!\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --job=0715efaac53e46e5a6bc81532969555b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris\"\n",
    "  },\n",
    "  \"description\": \"A pipeline that trains simple Iris classifier.\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"/train_iris.py\" ],\n",
    "    \"image\": \"seldonio/pachyderm-iris-trainer:0.1\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris-data\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify pipeline success\n",
    "\n",
    "Give pachyderm a moment to process the pipeline first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE STARTED      DURATION  RESTART PROGRESS  DL       UL      STATE   \n",
      "145ae50e43e24019b923b823e2813eeb iris     18 hours ago 4 seconds 0       1 + 0 / 1 3.005KiB 1.01KiB \u001b[32msuccess\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO BRANCH COMMIT                           FINISHED     SIZE    PROGRESS DESCRIPTION\n",
      "iris master 74976e9cc5e540cbb4d61d370b350518 18 hours ago 1.01KiB -         \n"
     ]
    }
   ],
   "source": [
    "!pachctl list commit iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME          TYPE SIZE    \n",
      "/model.joblib file 1.01KiB \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile metadata.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris-meta\"\n",
    "  },\n",
    "  \"description\": \"Copy model over and create seldon metadata based on model commit in pachyderm\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"-c\", \"import os; import pprint; pprint.pprint(os.environ)\" ],\n",
    "    \"image\": \"python:3\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile metadata.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris-meta\"\n",
    "  },\n",
    "  \"description\": \"Copy model over and create seldon metadata based on model commit in pachyderm\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"-c\", \"import os; import pprint; pprint.pprint(dict(os.environ))\" ],\n",
    "    \"image\": \"python:3\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl update pipeline -f metadata.json --reprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE  STARTED      DURATION  RESTART PROGRESS  DL       UL      STATE   \n",
      "033e4477c8644139b0a0c1c03ec10000 iris-meta 1 second ago -         0       0 + 0 / 0 0B       0B      \u001b[33mrunning\u001b[0m \n",
      "145ae50e43e24019b923b823e2813eeb iris      3 days ago   4 seconds 0       1 + 0 / 1 3.005KiB 1.01KiB \u001b[32msuccess\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DASH_PORT': 'tcp://10.0.5.82:8080',\n",
      " 'DASH_PORT_8080_TCP': 'tcp://10.0.5.82:8080',\n",
      " 'DASH_PORT_8080_TCP_ADDR': '10.0.5.82',\n",
      " 'DASH_PORT_8080_TCP_PORT': '8080',\n",
      " 'DASH_PORT_8080_TCP_PROTO': 'tcp',\n",
      " 'DASH_PORT_8081_TCP': 'tcp://10.0.5.82:8081',\n",
      " 'DASH_PORT_8081_TCP_ADDR': '10.0.5.82',\n",
      " 'DASH_PORT_8081_TCP_PORT': '8081',\n",
      " 'DASH_PORT_8081_TCP_PROTO': 'tcp',\n",
      " 'DASH_SERVICE_HOST': '10.0.5.82',\n",
      " 'DASH_SERVICE_PORT': '8080',\n",
      " 'DASH_SERVICE_PORT_DASH_HTTP': '8080',\n",
      " 'DASH_SERVICE_PORT_GRPC_PROXY_HTTP': '8081',\n",
      " 'ETCD_PORT': 'tcp://10.0.4.103:2379',\n",
      " 'ETCD_PORT_2379_TCP': 'tcp://10.0.4.103:2379',\n",
      " 'ETCD_PORT_2379_TCP_ADDR': '10.0.4.103',\n",
      " 'ETCD_PORT_2379_TCP_PORT': '2379',\n",
      " 'ETCD_PORT_2379_TCP_PROTO': 'tcp',\n",
      " 'ETCD_SERVICE_HOST': '10.0.4.103',\n",
      " 'ETCD_SERVICE_PORT': '2379',\n",
      " 'ETCD_SERVICE_PORT_CLIENT_PORT': '2379',\n",
      " 'GOOGLE_BUCKET': 'hub-b0-h3ix16qcrp',\n",
      " 'GOOGLE_CRED': '',\n",
      " 'GPG_KEY': 'E3FF2839C048B25C084DEBE9B26995E310250568',\n",
      " 'HOME': '/root',\n",
      " 'HOSTNAME': 'pipeline-iris-meta-v7-9twzx',\n",
      " 'KUBERNETES_PORT': 'tcp://10.0.0.1:443',\n",
      " 'KUBERNETES_PORT_443_TCP': 'tcp://10.0.0.1:443',\n",
      " 'KUBERNETES_PORT_443_TCP_ADDR': '10.0.0.1',\n",
      " 'KUBERNETES_PORT_443_TCP_PORT': '443',\n",
      " 'KUBERNETES_PORT_443_TCP_PROTO': 'tcp',\n",
      " 'KUBERNETES_SERVICE_HOST': '10.0.0.1',\n",
      " 'KUBERNETES_SERVICE_PORT': '443',\n",
      " 'KUBERNETES_SERVICE_PORT_HTTPS': '443',\n",
      " 'LANG': 'C.UTF-8',\n",
      " 'LOKI_LOGGING': 'true',\n",
      " 'LOKI_PORT': 'tcp://10.0.14.191:3100',\n",
      " 'LOKI_PORT_3100_TCP': 'tcp://10.0.14.191:3100',\n",
      " 'LOKI_PORT_3100_TCP_ADDR': '10.0.14.191',\n",
      " 'LOKI_PORT_3100_TCP_PORT': '3100',\n",
      " 'LOKI_PORT_3100_TCP_PROTO': 'tcp',\n",
      " 'LOKI_SERVICE_HOST': '10.0.14.191',\n",
      " 'LOKI_SERVICE_PORT': '3100',\n",
      " 'LOKI_SERVICE_PORT_HTTP_METRICS': '3100',\n",
      " 'PACHD_LB_PORT': 'tcp://10.0.7.214:31400',\n",
      " 'PACHD_LB_PORT_30600_TCP': 'tcp://10.0.7.214:30600',\n",
      " 'PACHD_LB_PORT_30600_TCP_ADDR': '10.0.7.214',\n",
      " 'PACHD_LB_PORT_30600_TCP_PORT': '30600',\n",
      " 'PACHD_LB_PORT_30600_TCP_PROTO': 'tcp',\n",
      " 'PACHD_LB_PORT_31400_TCP': 'tcp://10.0.7.214:31400',\n",
      " 'PACHD_LB_PORT_31400_TCP_ADDR': '10.0.7.214',\n",
      " 'PACHD_LB_PORT_31400_TCP_PORT': '31400',\n",
      " 'PACHD_LB_PORT_31400_TCP_PROTO': 'tcp',\n",
      " 'PACHD_LB_SERVICE_HOST': '10.0.7.214',\n",
      " 'PACHD_LB_SERVICE_PORT': '31400',\n",
      " 'PACHD_LB_SERVICE_PORT_API_GRPC_PORT': '31400',\n",
      " 'PACHD_LB_SERVICE_PORT_S3_GATEWAY_PORT': '30600',\n",
      " 'PACHD_PORT': 'tcp://10.0.14.152:30653',\n",
      " 'PACHD_PORT_30600_TCP': 'tcp://10.0.14.152:30600',\n",
      " 'PACHD_PORT_30600_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30600_TCP_PORT': '30600',\n",
      " 'PACHD_PORT_30600_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30650_TCP': 'tcp://10.0.14.152:30650',\n",
      " 'PACHD_PORT_30650_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30650_TCP_PORT': '30650',\n",
      " 'PACHD_PORT_30650_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30651_TCP': 'tcp://10.0.14.152:30651',\n",
      " 'PACHD_PORT_30651_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30651_TCP_PORT': '30651',\n",
      " 'PACHD_PORT_30651_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30652_TCP': 'tcp://10.0.14.152:30652',\n",
      " 'PACHD_PORT_30652_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30652_TCP_PORT': '30652',\n",
      " 'PACHD_PORT_30652_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30653_TCP': 'tcp://10.0.14.152:30653',\n",
      " 'PACHD_PORT_30653_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30653_TCP_PORT': '30653',\n",
      " 'PACHD_PORT_30653_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30654_TCP': 'tcp://10.0.14.152:30654',\n",
      " 'PACHD_PORT_30654_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30654_TCP_PORT': '30654',\n",
      " 'PACHD_PORT_30654_TCP_PROTO': 'tcp',\n",
      " 'PACHD_PORT_30999_TCP': 'tcp://10.0.14.152:30999',\n",
      " 'PACHD_PORT_30999_TCP_ADDR': '10.0.14.152',\n",
      " 'PACHD_PORT_30999_TCP_PORT': '30999',\n",
      " 'PACHD_PORT_30999_TCP_PROTO': 'tcp',\n",
      " 'PACHD_SERVICE_HOST': '10.0.14.152',\n",
      " 'PACHD_SERVICE_PORT': '30653',\n",
      " 'PACHD_SERVICE_PORT_API_GIT_PORT': '30999',\n",
      " 'PACHD_SERVICE_PORT_API_GRPC_PEER': '30653',\n",
      " 'PACHD_SERVICE_PORT_API_GRPC_PORT': '30650',\n",
      " 'PACHD_SERVICE_PORT_API_HTTP_PORT': '30652',\n",
      " 'PACHD_SERVICE_PORT_S3GATEWAY_PORT': '30600',\n",
      " 'PACHD_SERVICE_PORT_SAML_PORT': '30654',\n",
      " 'PACHD_SERVICE_PORT_TRACE_PORT': '30651',\n",
      " 'PACH_JOB_ID': '033e4477c8644139b0a0c1c03ec10000',\n",
      " 'PACH_NAMESPACE': 'default',\n",
      " 'PACH_OUTPUT_COMMIT_ID': 'd6df983db1b9439581280d6eaf3d6a19',\n",
      " 'PACH_ROOT': '/pach',\n",
      " 'PATH': '/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin',\n",
      " 'PEER_PORT': '653',\n",
      " 'PIPELINE_IRIS_META_V7_PORT': 'tcp://10.0.14.235:80',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP': 'tcp://10.0.14.235:80',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP_ADDR': '10.0.14.235',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP_PORT': '80',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP': 'tcp://10.0.14.235:9090',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP_ADDR': '10.0.14.235',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP_PORT': '9090',\n",
      " 'PIPELINE_IRIS_META_V7_PORT_9090_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_HOST': '10.0.14.235',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_PORT': '80',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_PORT_GRPC_PORT': '80',\n",
      " 'PIPELINE_IRIS_META_V7_SERVICE_PORT_PROMETHEUS_METRICS': '9090',\n",
      " 'PIPELINE_IRIS_V1_PORT': 'tcp://10.0.2.27:80',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP': 'tcp://10.0.2.27:80',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP_ADDR': '10.0.2.27',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP_PORT': '80',\n",
      " 'PIPELINE_IRIS_V1_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP': 'tcp://10.0.2.27:9090',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP_ADDR': '10.0.2.27',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP_PORT': '9090',\n",
      " 'PIPELINE_IRIS_V1_PORT_9090_TCP_PROTO': 'tcp',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_HOST': '10.0.2.27',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_PORT': '80',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_PORT_GRPC_PORT': '80',\n",
      " 'PIPELINE_IRIS_V1_SERVICE_PORT_PROMETHEUS_METRICS': '9090',\n",
      " 'PPS_ETCD_PREFIX': 'pachyderm/1.7.0/pachyderm_pps',\n",
      " 'PPS_PIPELINE_NAME': 'iris-meta',\n",
      " 'PPS_POD_NAME': 'pipeline-iris-meta-v7-9twzx',\n",
      " 'PPS_SPEC_COMMIT': 'e7b659d932a048b7baa8129f16e6aa9e',\n",
      " 'PPS_WORKER_GRPC_PORT': '80',\n",
      " 'PPS_WORKER_IP': '10.44.0.39',\n",
      " 'PYTHON_GET_PIP_SHA256': 'd4d62a0850fe0c2e6325b2cc20d818c580563de5a2038f917e3cb0e25280b4d1',\n",
      " 'PYTHON_GET_PIP_URL': 'https://github.com/pypa/get-pip/raw/5578af97f8b2b466f4cdbebe18a3ba2d48ad1434/get-pip.py',\n",
      " 'PYTHON_PIP_VERSION': '20.2.1',\n",
      " 'PYTHON_VERSION': '3.8.5',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT': 'tcp://10.0.4.11:80',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP': 'tcp://10.0.4.11:443',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP_ADDR': '10.0.4.11',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP_PORT': '443',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_443_TCP_PROTO': 'tcp',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP': 'tcp://10.0.4.11:80',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP_ADDR': '10.0.4.11',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP_PORT': '80',\n",
      " 'RELEASE_NAME_TRAEFIK_PORT_80_TCP_PROTO': 'tcp',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_HOST': '10.0.4.11',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_PORT': '80',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_PORT_HTTP': '80',\n",
      " 'RELEASE_NAME_TRAEFIK_SERVICE_PORT_HTTPS': '443',\n",
      " 'STORAGE_BACKEND': 'GOOGLE',\n",
      " 'iris': '/pfs/iris/model.joblib',\n",
      " 'iris_COMMIT': '74976e9cc5e540cbb4d61d370b350518'}\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --job 033e4477c8644139b0a0c1c03ec10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return logs from a job.\n",
      "\n",
      "Usage:\n",
      "  pachctl logs [--pipeline=<pipeline>|--job=<job>] [--datum=<datum>] [flags]\n",
      "\n",
      "Examples:\n",
      "\n",
      "# Return logs emitted by recent jobs in the \"filter\" pipeline\n",
      "$ pachctl logs --pipeline=filter\n",
      "\n",
      "# Return logs emitted by the job aedfa12aedf\n",
      "$ pachctl logs --job=aedfa12aedf\n",
      "\n",
      "# Return logs emitted by the pipeline \\\"filter\\\" while processing /apple.txt and a file with the hash 123aef\n",
      "$ pachctl logs --pipeline=filter --inputs=/apple.txt,123aef\n",
      "\n",
      "Flags:\n",
      "      --datum string      Filter for log lines for this datum (accepts datum ID)\n",
      "  -f, --follow            Follow logs as more are created.\n",
      "  -h, --help              help for logs\n",
      "      --inputs string     Filter for log lines generated while processing these files (accepts PFS paths or file hashes)\n",
      "  -j, --job string        Filter for log lines from this job (accepts job ID)\n",
      "      --master            Return log messages from the master process (pipeline must be set).\n",
      "  -p, --pipeline string   Filter the log for lines from this pipeline (accepts pipeline name)\n",
      "      --raw               Return log messages verbatim from server.\n",
      "  -t, --tail int          Lines of recent logs to display.\n",
      "      --worker            Return log messages from the worker process.\n",
      "\n",
      "Global Flags:\n",
      "      --no-color   Turn off colors.\n",
      "  -v, --verbose    Output verbose logs\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add trained model to remote S3 storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadata.yaml \n",
    "\n",
    "In metadata we can use Pachyderm's hash to version deployed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitId = !pachctl list commit iris --raw |jq -r .commit.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitId = commitId[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"metadata.yaml\", \"w\")\n",
    "\n",
    "f.write(f\"\"\"name: iris\n",
    "versions: [iris/pachyderm:{commitId}]\n",
    "platform: sklearn\n",
    "inputs:\n",
    "- datatype: BYTES\n",
    "  name: input\n",
    "  shape: [ 1, 4 ]\n",
    "outputs:\n",
    "- datatype: BYTES\n",
    "  name: output\n",
    "  shape: [ 3 ]\"\"\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Extend the above pachyderm pipeline to output to a repo which contains the model from the previous pipeline stage along with the metadata.yml with \n",
    "\n",
    "Then we can automatically generate the Seldon metadata for a versioned model whenever the data changes, which is cool.\n",
    "\n",
    "Also: how to access the Pach S3 gateway? Look at the docs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metadata to Pachyderm\n",
    "\n",
    "This is so that Seldon can fetch it via Pachyderm's S3 gateway, which allows Seldon to access files in Pachyderm using the S3 protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.yaml: 203 B / 203 B [================================] 100.00% ? p/s 0s\n",
      "cannot start a commit on an output branch\n"
     ]
    }
   ],
   "source": [
    "!pachctl put file iris@master -f metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bucket for our trained model and push it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket created successfully `minio-seldon/pachyderm-iris`.\n",
      "`model.joblib` -> `minio-seldon/pachyderm-iris/model.joblib`\n",
      "Total: 0 B, Transferred: 1.01 KiB, Speed: 146.70 KiB/s\n",
      "`metadata.yaml` -> `minio-seldon/pachyderm-iris/metadata.yaml`\n",
      "Total: 0 B, Transferred: 205 B, Speed: 24.81 KiB/s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mc mb minio-seldon/pachyderm-iris -p\n",
    "\n",
    "mc cp model.joblib minio-seldon/pachyderm-iris/\n",
    "mc cp metadata.yaml minio-seldon/pachyderm-iris/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2020-05-24 18:53:00 BST] \u001b[0m\u001b[33m   205B \u001b[0m\u001b[1mmetadata.yaml\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2020-05-24 18:53:00 BST] \u001b[0m\u001b[33m 1.0KiB \u001b[0m\u001b[1mmodel.joblib\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mc ls minio-seldon/pachyderm-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy sklearn server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting secret.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile secret.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: seldon-init-container-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "  AWS_ENDPOINT_URL: http://minio.minio-system.svc.cluster.local:9000\n",
    "  USE_SSL: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/seldon-init-container-secret configured\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f secret.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: pachyderm-sklearn\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/executor: \"true\"\n",
    "  name: iris\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: s3://pachyderm-iris\n",
    "      envSecretRefName: seldon-init-container-secret\n",
    "      name: classifier\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/pachyderm-sklearn created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f deploy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"pachyderm-sklearn-default-0-classifier\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"pachyderm-sklearn-default-0-classifier\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=pachyderm-sklearn -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"names\": [\n",
      "      \"t:0\",\n",
      "      \"t:1\",\n",
      "      \"t:2\"\n",
      "    ],\n",
      "    \"ndarray\": [\n",
      "      [\n",
      "        0.9548873249364185,\n",
      "        0.04505474761561256,\n",
      "        5.792744796895459e-05\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\":{\"ndarray\":[[5.964, 4.006, 2.081, 1.031]]}}' \\\n",
    "    http://localhost:8003/seldon/seldon/pachyderm-sklearn/api/v1.0/predictions  | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model metadata (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"name\": \"input\",\n",
      "      \"shape\": [\n",
      "        1,\n",
      "        4\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"name\": \"iris\",\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"name\": \"output\",\n",
      "      \"shape\": [\n",
      "        3\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"platform\": \"sklearn\",\n",
      "  \"versions\": [\n",
      "    \"iris/pachyderm:f8849a38b3f64c4b8998abf1f732f486\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s http://localhost:8003/seldon/seldon/pachyderm-sklearn/api/v1.0/metadata/classifier | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"pachyderm-sklearn\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deploy.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
