{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Examples for SKlearn Prepackaged Server trained with Pachyderm and deployed to MinIO\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    " * A kubernetes cluster with kubectl configured\n",
    " * curl\n",
    " * pygmentize\n",
    " * Python 3.7 locally (3.8 does not work, use pyenv if necessary)\n",
    "\n",
    "TODO: test with local minikube, ensure example works end to end with a totally fresh cluster (rather than working on pachub cluster and skipping some bits)\n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](seldon_core_setup.ipynb) to setup Seldon Core with an ingress.\n",
    "\n",
    "\n",
    "## Setup MinIO (TODO: remove this section)\n",
    "\n",
    "Use the provided [notebook](../../../notebooks/minio_setup.ipynb) to install Minio in your cluster and configure `mc` CLI tool. \n",
    "Instructions [also online](./minio_setup.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python dependencies\n",
    "\n",
    "This tutorial will require you to install pandas and scikit-learn in followint versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit-learn == 0.20.3\n",
      "numpy >= 1.8.2\n",
      "joblib >= 0.13.0\n",
      "pandas >= 1.0.1\n",
      "PyYAML >= 5.3\n"
     ]
    }
   ],
   "source": [
    "!cat iris-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can do it by issuing following command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn==0.20.3\n",
      "  Using cached scikit_learn-0.20.3-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "Collecting numpy>=1.8.2\n",
      "  Using cached numpy-1.19.1-cp37-cp37m-manylinux2010_x86_64.whl (14.5 MB)\n",
      "Collecting joblib>=0.13.0\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting pandas>=1.0.1\n",
      "  Using cached pandas-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (10.5 MB)\n",
      "Collecting PyYAML>=5.3\n",
      "  Using cached PyYAML-5.3.1.tar.gz (269 kB)\n",
      "Collecting scipy>=0.13.3\n",
      "  Downloading scipy-1.5.2-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.9 MB 2.9 MB/s eta 0:00:01    |▊                               | 573 kB 1.8 MB/s eta 0:00:15\n",
      "\u001b[?25hCollecting python-dateutil>=2.7.3\n",
      "  Using cached python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\n",
      "Collecting pytz>=2017.2\n",
      "  Downloading pytz-2020.1-py2.py3-none-any.whl (510 kB)\n",
      "\u001b[K     |████████████████████████████████| 510 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Using legacy setup.py install for PyYAML, since package 'wheel' is not installed.\n",
      "Installing collected packages: numpy, scipy, scikit-learn, joblib, six, python-dateutil, pytz, pandas, PyYAML\n",
      "    Running setup.py install for PyYAML ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed PyYAML-5.3.1 joblib-0.16.0 numpy-1.19.1 pandas-1.1.0 python-dateutil-2.8.1 pytz-2020.1 scikit-learn-0.20.3 scipy-1.5.2 six-1.15.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2.1 is available.\n",
      "You should consider upgrading via the '/home/luke/.pyenv/versions/3.7.8/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r iris-trainer/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Pachyderm CLI (pachctl) client tool\n",
    "\n",
    "Follow steps relevant to your platform from official [documentation](https://docs.pachyderm.com/latest/getting_started/local_installation/#install-pachctl) in order to get the `pachctl` command line tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify correct client installation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.0-3ad6aa7344f90eeebedb6235eeb561bdded45879\n"
     ]
    }
   ],
   "source": [
    "!pachctl version --client-only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Pachyderm in cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pachctl deploy Pachyderm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/pachyderm created\n",
      "serviceaccount/pachyderm created\n",
      "serviceaccount/pachyderm-worker created\n",
      "clusterrole.rbac.authorization.k8s.io/pachyderm created\n",
      "clusterrolebinding.rbac.authorization.k8s.io/pachyderm created\n",
      "role.rbac.authorization.k8s.io/pachyderm-worker created\n",
      "rolebinding.rbac.authorization.k8s.io/pachyderm-worker created\n",
      "deployment.apps/etcd created\n",
      "service/etcd created\n",
      "service/pachd created\n",
      "service/pachd-peer created\n",
      "deployment.apps/pachd created\n",
      "service/dash created\n",
      "deployment.apps/dash created\n",
      "secret/pachyderm-storage-secret created\n",
      "\n",
      "Pachyderm is launching. Check its status with \"kubectl get all\"\n",
      "Once launched, access the dashboard by running \"pachctl port-forward\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "kubectl create ns pachyderm\n",
    "pachctl deploy local --no-expose-docker-socket --namespace pachyderm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error from server (NotFound): deployments.apps \"pachd\" not found\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deployment pachd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### port-forward pachyderm to localhost\n",
    "\n",
    "in separate terminal:\n",
    "\n",
    "```bash\n",
    "pachctl port-forward\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model using Pachyderm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And training data to Pachyderm \"iris-input\" repository"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use the helper python script to pull iris training data from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36msklearn\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m datasets\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\n",
      "\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGetting Iris Dataset\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    iris = datasets.load_iris()\n",
      "    X, y = iris.data, iris.target\n",
      "\n",
      "    data = pd.DataFrame(\n",
      "        data=np.c_[iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mdata\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m], iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m]],\n",
      "        columns=iris[\u001b[33m\"\u001b[39;49;00m\u001b[33mfeature_names\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m] + [\u001b[33m\"\u001b[39;49;00m\u001b[33mtarget\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m],\n",
      "    )\n",
      "\n",
      "    data.to_csv(\u001b[33m\"\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, index=\u001b[34mFalse\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mIris dataset saved to \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33mdata.csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m file\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\n",
      "    main()\n"
     ]
    }
   ],
   "source": [
    "!pygmentize get-data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke/Projects/Pachyderm/seldon-core/examples/pachyderm\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/luke/.pyenv/versions/3.7.8/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "Getting Iris Dataset\n",
      "Iris dataset saved to 'data.csv' file\n"
     ]
    }
   ],
   "source": [
    "!python get-data.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put produced `data.csv` file into Pachyderm's  `iris-input` repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      CREATED      SIZE (MASTER) ACCESS LEVEL \n",
      "iris-data 1 second ago 0B            OWNER         \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pachctl create repo iris-data\n",
    "pachctl list repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we use following python script to pull training dataset from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO      BRANCH COMMIT                           FINISHED     SIZE     PROGRESS DESCRIPTION\n",
      "iris-data master b6f21966b1ca434281bc23fb751ab5d9 1 second ago 3.005KiB -         \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "data.csv: 3.00 KiB / 3.00 KiB [===================================================] 100.00% ? p/s 0s"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pachctl put file iris-data@master -f data.csv\n",
    "pachctl list commit iris-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME      TYPE SIZE     \n",
      "/data.csv file 3.005KiB \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris-data@master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Pachyderm pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pachyderm Pipeline is defined by the following file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting train.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris\"\n",
    "  },\n",
    "  \"description\": \"A pipeline that trains simple Iris classifier.\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"/train_iris.py\" ],\n",
    "    \"image\": \"seldonio/pachyderm-iris-trainer:0.1\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris-data\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl create pipeline -f train.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify pipeline success\n",
    "\n",
    "Give pachyderm a moment to process the pipeline first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE STARTED      DURATION  RESTART PROGRESS  DL       UL      STATE   \n",
      "145ae50e43e24019b923b823e2813eeb iris     18 hours ago 4 seconds 0       1 + 0 / 1 3.005KiB 1.01KiB \u001b[32msuccess\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO BRANCH COMMIT                           FINISHED     SIZE    PROGRESS DESCRIPTION\n",
      "iris master 74976e9cc5e540cbb4d61d370b350518 18 hours ago 1.01KiB -         \n"
     ]
    }
   ],
   "source": [
    "!pachctl list commit iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME          TYPE SIZE    \n",
      "/model.joblib file 1.01KiB \n"
     ]
    }
   ],
   "source": [
    "!pachctl list file iris@master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile metadata.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris-meta\"\n",
    "  },\n",
    "  \"description\": \"Copy model over and create seldon metadata based on model commit in pachyderm\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"-c\", \"import os; import pprint; pprint.pprint(os.environ)\" ],\n",
    "    \"image\": \"python:3\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting metadata.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile metadata.json\n",
    "\n",
    "{\n",
    "  \"pipeline\": {\n",
    "    \"name\": \"iris-meta\"\n",
    "  },\n",
    "  \"description\": \"Copy model over and create seldon metadata based on model commit in pachyderm\",\n",
    "  \"transform\": {\n",
    "    \"cmd\": [ \"python3\", \"-c\", \"import os; print(os.environ)\" ],\n",
    "    \"image\": \"python:3\"\n",
    "  },\n",
    "  \"input\": {\n",
    "    \"pfs\": {\n",
    "      \"repo\": \"iris\",\n",
    "      \"glob\": \"/*\"\n",
    "    }\n",
    "  }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl update pipeline -f metadata.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID                               PIPELINE  STARTED       DURATION  RESTART PROGRESS  DL       UL      STATE   \n",
      "1a2ffcd611b54fcbb7207267bc8add2c iris-meta 9 seconds ago 1 second  0       0 + 1 / 1 0B       0B      \u001b[32msuccess\u001b[0m \n",
      "145ae50e43e24019b923b823e2813eeb iris      3 days ago    4 seconds 0       1 + 0 / 1 3.005KiB 1.01KiB \u001b[32msuccess\u001b[0m \n"
     ]
    }
   ],
   "source": [
    "!pachctl list job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pachctl logs --job 1a2ffcd611b54fcbb7207267bc8add2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return logs from a job.\n",
      "\n",
      "Usage:\n",
      "  pachctl logs [--pipeline=<pipeline>|--job=<job>] [--datum=<datum>] [flags]\n",
      "\n",
      "Examples:\n",
      "\n",
      "# Return logs emitted by recent jobs in the \"filter\" pipeline\n",
      "$ pachctl logs --pipeline=filter\n",
      "\n",
      "# Return logs emitted by the job aedfa12aedf\n",
      "$ pachctl logs --job=aedfa12aedf\n",
      "\n",
      "# Return logs emitted by the pipeline \\\"filter\\\" while processing /apple.txt and a file with the hash 123aef\n",
      "$ pachctl logs --pipeline=filter --inputs=/apple.txt,123aef\n",
      "\n",
      "Flags:\n",
      "      --datum string      Filter for log lines for this datum (accepts datum ID)\n",
      "  -f, --follow            Follow logs as more are created.\n",
      "  -h, --help              help for logs\n",
      "      --inputs string     Filter for log lines generated while processing these files (accepts PFS paths or file hashes)\n",
      "  -j, --job string        Filter for log lines from this job (accepts job ID)\n",
      "      --master            Return log messages from the master process (pipeline must be set).\n",
      "  -p, --pipeline string   Filter the log for lines from this pipeline (accepts pipeline name)\n",
      "      --raw               Return log messages verbatim from server.\n",
      "  -t, --tail int          Lines of recent logs to display.\n",
      "      --worker            Return log messages from the worker process.\n",
      "\n",
      "Global Flags:\n",
      "      --no-color   Turn off colors.\n",
      "  -v, --verbose    Output verbose logs\n"
     ]
    }
   ],
   "source": [
    "!pachctl logs --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add trained model to remote S3 storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create metadata.yaml \n",
    "\n",
    "In metadata we can use Pachyderm's hash to version deployed models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitId = !pachctl list commit iris --raw |jq -r .commit.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "commitId = commitId[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"metadata.yaml\", \"w\")\n",
    "\n",
    "f.write(f\"\"\"name: iris\n",
    "versions: [iris/pachyderm:{commitId}]\n",
    "platform: sklearn\n",
    "inputs:\n",
    "- datatype: BYTES\n",
    "  name: input\n",
    "  shape: [ 1, 4 ]\n",
    "outputs:\n",
    "- datatype: BYTES\n",
    "  name: output\n",
    "  shape: [ 3 ]\"\"\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "Extend the above pachyderm pipeline to output to a repo which contains the model from the previous pipeline stage along with the metadata.yml with \n",
    "\n",
    "Then we can automatically generate the Seldon metadata for a versioned model whenever the data changes, which is cool.\n",
    "\n",
    "Also: how to access the Pach S3 gateway? Look at the docs..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metadata to Pachyderm\n",
    "\n",
    "This is so that Seldon can fetch it via Pachyderm's S3 gateway, which allows Seldon to access files in Pachyderm using the S3 protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata.yaml: 203 B / 203 B [================================] 100.00% ? p/s 0s\n",
      "cannot start a commit on an output branch\n"
     ]
    }
   ],
   "source": [
    "!pachctl put file iris@master -f metadata.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create bucket for our trained model and push it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket created successfully `minio-seldon/pachyderm-iris`.\n",
      "`model.joblib` -> `minio-seldon/pachyderm-iris/model.joblib`\n",
      "Total: 0 B, Transferred: 1.01 KiB, Speed: 146.70 KiB/s\n",
      "`metadata.yaml` -> `minio-seldon/pachyderm-iris/metadata.yaml`\n",
      "Total: 0 B, Transferred: 205 B, Speed: 24.81 KiB/s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mc mb minio-seldon/pachyderm-iris -p\n",
    "\n",
    "mc cp model.joblib minio-seldon/pachyderm-iris/\n",
    "mc cp metadata.yaml minio-seldon/pachyderm-iris/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[m\u001b[32m[2020-05-24 18:53:00 BST] \u001b[0m\u001b[33m   205B \u001b[0m\u001b[1mmetadata.yaml\u001b[0m\n",
      "\u001b[0m\u001b[m\u001b[32m[2020-05-24 18:53:00 BST] \u001b[0m\u001b[33m 1.0KiB \u001b[0m\u001b[1mmodel.joblib\u001b[0m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!mc ls minio-seldon/pachyderm-iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy sklearn server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting secret.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile secret.yaml\n",
    "\n",
    "apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: seldon-init-container-secret\n",
    "type: Opaque\n",
    "stringData:\n",
    "  AWS_ACCESS_KEY_ID: minioadmin\n",
    "  AWS_SECRET_ACCESS_KEY: minioadmin\n",
    "  AWS_ENDPOINT_URL: http://minio.minio-system.svc.cluster.local:9000\n",
    "  USE_SSL: \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/seldon-init-container-secret configured\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f secret.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting deploy.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile deploy.yaml\n",
    "\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: pachyderm-sklearn\n",
    "spec:\n",
    "  annotations:\n",
    "    seldon.io/executor: \"true\"\n",
    "  name: iris\n",
    "  predictors:\n",
    "  - componentSpecs:\n",
    "    graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: s3://pachyderm-iris\n",
    "      envSecretRefName: seldon-init-container-secret\n",
    "      name: classifier\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/pachyderm-sklearn created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f deploy.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"pachyderm-sklearn-default-0-classifier\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"pachyderm-sklearn-default-0-classifier\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=pachyderm-sklearn -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"data\": {\n",
      "    \"names\": [\n",
      "      \"t:0\",\n",
      "      \"t:1\",\n",
      "      \"t:2\"\n",
      "    ],\n",
      "    \"ndarray\": [\n",
      "      [\n",
      "        0.9548873249364185,\n",
      "        0.04505474761561256,\n",
      "        5.792744796895459e-05\n",
      "      ]\n",
      "    ]\n",
      "  },\n",
      "  \"meta\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s -X POST -H 'Content-Type: application/json' \\\n",
    "    -d '{\"data\":{\"ndarray\":[[5.964, 4.006, 2.081, 1.031]]}}' \\\n",
    "    http://localhost:8003/seldon/seldon/pachyderm-sklearn/api/v1.0/predictions  | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model metadata (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"inputs\": [\n",
      "    {\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"name\": \"input\",\n",
      "      \"shape\": [\n",
      "        1,\n",
      "        4\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"name\": \"iris\",\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"datatype\": \"BYTES\",\n",
      "      \"name\": \"output\",\n",
      "      \"shape\": [\n",
      "        3\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"platform\": \"sklearn\",\n",
      "  \"versions\": [\n",
      "    \"iris/pachyderm:f8849a38b3f64c4b8998abf1f732f486\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "curl -s http://localhost:8003/seldon/seldon/pachyderm-sklearn/api/v1.0/metadata/classifier | jq ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"pachyderm-sklearn\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f deploy.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
